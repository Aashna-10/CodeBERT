{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e973c8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import torch\\nfrom transformers import AutoModel, AutoTokenizer\\nimport torch.nn.functional as F'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from typing import List, Type\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "import code_bert_score\n",
    "\"\"\"import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch.nn.functional as F\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2139e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Configuration: Adjust these paths as necessary for your environment\n",
    "# ------------------------------------------------------------------------------\n",
    "BASE_PATH = \"v3/\"\n",
    "PROBLEM_STATEMENTS_PATH = os.path.join(BASE_PATH, \"problem_statements_v3\")\n",
    "CORRECT_SOLUTIONS_PATH = os.path.join(BASE_PATH, \"correct_solutions_v3\")\n",
    "INCORRECT_SOLUTIONS_PATH = os.path.join(BASE_PATH, \"incorrect_solutions_v3\")\n",
    "RUBRICS_PATH = os.path.join(BASE_PATH, \"rubrics_v3\")\n",
    "RESULTS_CSV = os.path.join(BASE_PATH, \"our_results_new_withouthandout_name.csv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e19e0c25",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Please set your OpenAI API key in the environment variable 'OPENAI_API_KEY'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[152], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Ensure the environment variable is set for OpenAI\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set your OpenAI API key in the environment variable \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: Please set your OpenAI API key in the environment variable 'OPENAI_API_KEY'."
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Ensure the environment variable is set for OpenAI\n",
    "# ------------------------------------------------------------------------------\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    raise EnvironmentError(\n",
    "        f\"Please set your OpenAI API key in the environment variable 'OPENAI_API_KEY'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49dd613",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7feafe",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------\n",
    "Define Pydantic Classes for Each Prompt's Response\n",
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d87e5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Prompt1Response(BaseModel):\n",
    "    score: int\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2eaab8ac",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Prompt2Response(BaseModel):\n",
    "    score: int\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f304b693",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Prompt3Response(BaseModel):\n",
    "    score: int\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6abbfcfa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Prompt4Response(BaseModel):\n",
    "    modified_score: int\n",
    "    reasoning: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c64ffd",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------\n",
    "Helper Functions\n",
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3757c264",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "05a93dcc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_files_in_folder(folder_path):\n",
    "    return sorted(\n",
    "        [\n",
    "            os.path.join(folder_path, fname)\n",
    "            for fname in os.listdir(folder_path)\n",
    "            if os.path.isfile(os.path.join(folder_path, fname))\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eb305d67",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def filter_matching_solutions(problem_base, solution_files):\n",
    "    \"\"\"\n",
    "    Filters solution files to only include those matching the problem's base name.\n",
    "    This ensures that only solution files associated with the specific problem are included.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        sf for sf in solution_files\n",
    "        if os.path.basename(sf).startswith(problem_base + \"-\") or os.path.basename(sf).startswith(problem_base + \"_solution\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4ec29ee4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_prompt(prompt: str, response_model: Type[BaseModel]):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format=response_model\n",
    "    )\n",
    "    return completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7f3a3560",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def save_results_to_csv(rows):\n",
    "    file_exists = os.path.isfile(RESULTS_CSV)\n",
    "    with open(RESULTS_CSV, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if not file_exists:\n",
    "            writer.writerow([\n",
    "                \"Problem\",\n",
    "                \"Submitted Code\",\n",
    "                \"Score\"\n",
    "            ])\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3de85",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------\n",
    "Prompt Definitions\n",
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e729596c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prompt1(handout, sample_solution, submitted_code):\n",
    "    return f\"\"\"\n",
    "Evaluate the student's code based on the problem description and the provided example solution.\n",
    "\n",
    "Problem Description:\n",
    "{handout}\n",
    "\n",
    "Model (Correct) Solution:\n",
    "{sample_solution}\n",
    "\n",
    "Student Code:\n",
    "{submitted_code}\n",
    "\n",
    "Provide a score (1-10) and feedback in structured JSON format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "1a54af9a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prompt2(handout, sample_solution, submitted_code):\n",
    "    return f\"\"\"\n",
    "You are an experienced computer science professor who has taught Python programming for over a decade.\n",
    "Your teaching style emphasizes clarity, functionality, and efficiency in code. You are committed to helping \n",
    "students understand programming concepts while fostering their ability to write maintainable and error-free code.\n",
    "\n",
    "Below is a problem description, an example solution, and a student's code.\n",
    "Evaluate the student's code, provide detailed functional suggestions to fix the issues, and assign a score (1-10).\n",
    "The score must be an integer in the range of 1 to 10.\n",
    "\n",
    "Problem Description:\n",
    "{handout}\n",
    "\n",
    "Model (Correct) Solution:\n",
    "{sample_solution}\n",
    "\n",
    "Student Code:\n",
    "{submitted_code}\n",
    "\n",
    "Provide your response in structured JSON format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "97385395",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prompt3(handout, sample_solution, submitted_code, rubric):\n",
    "    return f\"\"\"\n",
    "You are a computer science professor teaching introductory programming using Python.\n",
    "\n",
    "Below is a problem description, an example solution, and a student's code. \n",
    "Use the rubric provided to evaluate the code and provide a score (1-10) and feedback. \n",
    "The score must be an integer in the range of 1 to 10.\n",
    "\n",
    "Problem Description:\n",
    "{handout}\n",
    "\n",
    "Model (Correct) Solution:\n",
    "{sample_solution}\n",
    "\n",
    "Student Code:\n",
    "{submitted_code}\n",
    "\n",
    "Rubric:\n",
    "{rubric}\n",
    "\n",
    "Provide the response in structured JSON format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "cc34771c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prompt5(handout, sample_solution, submitted_code, rubric, previous_feedback, previous_score):\n",
    "    return f\"\"\"\n",
    "You are a computer science professor teaching introductory programming using Python.\n",
    "\n",
    "Below is the original problem description, an example solution, and the student's code. \n",
    "You also have the rubric, the previously assigned feedback, and the previous score. \n",
    "Reevaluate the student's score based on that feedback and the rubric. \n",
    "Decide if the score should remain the same or change. Justify your decision. \n",
    "The modified score must be an integer in the range of 1 to 10.\n",
    "\n",
    "Problem Description:\n",
    "{handout}\n",
    "\n",
    "Model (Correct) Solution:\n",
    "{sample_solution}\n",
    "\n",
    "Student Code:\n",
    "{submitted_code}\n",
    "\n",
    "Rubric:\n",
    "{rubric}\n",
    "\n",
    "Previous Feedback:\n",
    "{previous_feedback}\n",
    "\n",
    "Previous Score: {previous_score}\n",
    "\n",
    "Provide the response in structured JSON format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798469d",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------\n",
    "Main Script\n",
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bd7a5461",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def tokenize_code(code):\\n    inputs = tokenizer(code, return_tensors='pt', padding=True, truncation=True)\\n    return inputs\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def tokenize_code(code):\n",
    "    inputs = tokenizer(code, return_tensors='pt', padding=True, truncation=True)\n",
    "    return inputs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3591f122",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_code_embeddings(tokenized_code):\\n    # Get embeddings for the code using CodeBERT model\\n    with torch.no_grad():\\n        outputs = model(**tokenized_code)\\n        embeddings = outputs.last_hidden_state.mean(dim=1)  # Get the mean of token embeddings\\n    return embeddings'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def get_code_embeddings(tokenized_code):\n",
    "    # Get embeddings for the code using CodeBERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenized_code)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Get the mean of token embeddings\n",
    "    return embeddings\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "92d06319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def cosine_similarity(embedding1, embedding2):\\n    # Compute cosine similarity between two embeddings\\n    return F.cosine_similarity(embedding1, embedding2)'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def cosine_similarity(embedding1, embedding2):\n",
    "    # Compute cosine similarity between two embeddings\n",
    "    return F.cosine_similarity(embedding1, embedding2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fc296ad4-1950-4685-a3dd-f8545a21b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expected_score(input_string):\n",
    "    # Check if input contains \"solution\"\n",
    "    if \"solution\" in input_string:\n",
    "        return 1\n",
    "    else:\n",
    "        # Find the position of \"pt\" in the input string\n",
    "        pos = input_string.find(\"pt\")\n",
    "        if pos != -1 and pos > 0:\n",
    "            # Get the character that precedes \"pt\" and convert it to an integer\n",
    "            preceding_char = input_string[pos - 1]\n",
    "            if preceding_char.isdigit():\n",
    "                preceding_int = int(preceding_char)\n",
    "                return preceding_int / 10\n",
    "        # If conditions are not met, you can return a default value (e.g., 0)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1b63c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    problem_files = get_files_in_folder(PROBLEM_STATEMENTS_PATH)\n",
    "    correct_solution_files = get_files_in_folder(CORRECT_SOLUTIONS_PATH)\n",
    "    incorrect_solution_files = get_files_in_folder(INCORRECT_SOLUTIONS_PATH)\n",
    "\n",
    "    for problem_file in tqdm(problem_files, desc=\"Evaluating problem statements\"):\n",
    "        problem_base = os.path.splitext(os.path.basename(problem_file))[0]\n",
    "        main_name = problem_base.split(\"_statement\")[0]\n",
    "\n",
    "        handout = read_file(problem_file)\n",
    "        rubric_path = os.path.join(RUBRICS_PATH, f\"{main_name}_rubric.txt\")\n",
    "        solution_path = os.path.join(CORRECT_SOLUTIONS_PATH, f\"{main_name}_solution.txt\")\n",
    "\n",
    "        if not os.path.isfile(rubric_path):\n",
    "            print(f\"Rubric file not found for {main_name}: {rubric_path}\")\n",
    "            continue\n",
    "        if not os.path.isfile(solution_path):\n",
    "            print(f\"Solution file not found for {main_name}: {solution_path}\")\n",
    "            continue\n",
    "\n",
    "        rubric = read_file(rubric_path)\n",
    "        sample_solution = read_file(solution_path)\n",
    "\n",
    "        # Filter solution files to match only the current problem\n",
    "        all_solution_files = filter_matching_solutions(\n",
    "            main_name,\n",
    "            correct_solution_files + incorrect_solution_files\n",
    "        )\n",
    "\n",
    "        if not all_solution_files:\n",
    "            print(f\"No matching solution files found for problem '{main_name}'\")\n",
    "            continue\n",
    "\n",
    "        for solution_file in tqdm(all_solution_files, desc=f\"Evaluating solutions for {main_name}\", leave=False):\n",
    "            # ------------------------------------------------------------------------------\n",
    "            # handout is the specfic problem statement\n",
    "            # sample_solution is the model code/ complete correct solution\n",
    "            # submitted_code is the code sent in for submission\n",
    "            # place your function calls here\n",
    "            # all vars will be strings that can be passes as inputs to your function\n",
    "            # ------------------------------------------------------------------------------\n",
    "            submitted_code = read_file(solution_file)\n",
    "\n",
    "            code = [submitted_code]\n",
    "            reference_code = [sample_solution]\n",
    "            pred_results = code_bert_score.score(cands = code, refs = reference_code, lang = \"python\")\n",
    "            f3_value = (pred_results[3]).item()\n",
    "        \n",
    "\n",
    "            \"\"\"# Tokenize both the code and the reference\n",
    "            tokenized_code = tokenize_code(submitted_code)\n",
    "            tokenized_reference = tokenize_code(sample_solution)\n",
    "\n",
    "            # Get embeddings for both code and reference code\n",
    "            code_embedding = get_code_embeddings(tokenized_code)\n",
    "            reference_embedding = get_code_embeddings(tokenized_reference)\n",
    "\n",
    "            similarity_score = cosine_similarity(code_embedding, reference_embedding)\"\"\"\n",
    "            \n",
    "            \n",
    "\n",
    "            # ------------------------------------------------------------------------------\n",
    "            # your output values can be added to the row column here in this file\n",
    "            # ------------------------------------------------------------------------------\n",
    "            row = [\n",
    "                problem_base,\n",
    "                get_expected_score(os.path.basename(solution_file)),\n",
    "                f3_value\n",
    "            ]\n",
    "\n",
    "            save_results_to_csv([row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef9f80",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------\n",
    "Entrypoint\n",
    "------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ea6d5f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating problem statements:   0%|                                                                                                                                               | 0/10 [00:00<?, ?it/s]\n",
      "Evaluating solutions for problem10:   0%|                                                                                                                                           | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem10:  17%|█████████████████████▊                                                                                                             | 1/6 [00:02<00:13,  2.75s/it]\u001b[A\n",
      "Evaluating solutions for problem10:  33%|███████████████████████████████████████████▋                                                                                       | 2/6 [00:05<00:10,  2.53s/it]\u001b[A\n",
      "Evaluating solutions for problem10:  50%|█████████████████████████████████████████████████████████████████▌                                                                 | 3/6 [00:07<00:07,  2.44s/it]\u001b[A\n",
      "Evaluating solutions for problem10:  67%|███████████████████████████████████████████████████████████████████████████████████████▎                                           | 4/6 [00:10<00:05,  2.60s/it]\u001b[A\n",
      "Evaluating solutions for problem10:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                     | 5/6 [00:12<00:02,  2.45s/it]\u001b[A\n",
      "Evaluating solutions for problem10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:14<00:00,  2.42s/it]\u001b[A\n",
      "Evaluating problem statements:  10%|█████████████▌                                                                                                                         | 1/10 [00:14<02:13, 14.85s/it]\u001b[A\n",
      "Evaluating solutions for problem1:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem1:  17%|██████████████████████                                                                                                              | 1/6 [00:02<00:13,  2.77s/it]\u001b[A\n",
      "Evaluating solutions for problem1:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:06<00:13,  3.42s/it]\u001b[A\n",
      "Evaluating solutions for problem1:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [00:10<00:11,  3.67s/it]\u001b[A\n",
      "Evaluating solutions for problem1:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [00:15<00:08,  4.06s/it]\u001b[A\n",
      "Evaluating solutions for problem1:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [00:19<00:03,  3.95s/it]\u001b[A\n",
      "Evaluating solutions for problem1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:22<00:00,  3.86s/it]\u001b[A\n",
      "Evaluating problem statements:  20%|███████████████████████████                                                                                                            | 2/10 [00:37<02:35, 19.48s/it]\u001b[A\n",
      "Evaluating solutions for problem2:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem2:  17%|██████████████████████                                                                                                              | 1/6 [00:02<00:12,  2.56s/it]\u001b[A\n",
      "Evaluating solutions for problem2:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:06<00:13,  3.34s/it]\u001b[A\n",
      "Evaluating solutions for problem2:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [00:10<00:11,  3.83s/it]\u001b[A\n",
      "Evaluating solutions for problem2:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [00:14<00:07,  3.83s/it]\u001b[A\n",
      "Evaluating solutions for problem2:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [00:18<00:03,  3.81s/it]\u001b[A\n",
      "Evaluating solutions for problem2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:22<00:00,  3.96s/it]\u001b[A\n",
      "Evaluating problem statements:  30%|████████████████████████████████████████▌                                                                                              | 3/10 [01:00<02:26, 20.97s/it]\u001b[A\n",
      "Evaluating solutions for problem3:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem3:  17%|██████████████████████                                                                                                              | 1/6 [00:02<00:13,  2.68s/it]\u001b[A\n",
      "Evaluating solutions for problem3:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:06<00:13,  3.40s/it]\u001b[A\n",
      "Evaluating solutions for problem3:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [00:10<00:10,  3.63s/it]\u001b[A\n",
      "Evaluating solutions for problem3:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [00:14<00:07,  3.81s/it]\u001b[A\n",
      "Evaluating solutions for problem3:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [00:18<00:03,  3.94s/it]\u001b[A\n",
      "Evaluating solutions for problem3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:22<00:00,  3.96s/it]\u001b[A\n",
      "Evaluating problem statements:  40%|██████████████████████████████████████████████████████                                                                                 | 4/10 [01:23<02:10, 21.67s/it]\u001b[A\n",
      "Evaluating solutions for problem4:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem4:  17%|██████████████████████                                                                                                              | 1/6 [00:04<00:20,  4.15s/it]\u001b[A\n",
      "Evaluating solutions for problem4:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:11<00:23,  5.76s/it]\u001b[A\n",
      "Evaluating solutions for problem4:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [00:18<00:19,  6.38s/it]\u001b[A\n",
      "Evaluating solutions for problem4:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [00:25<00:13,  6.65s/it]\u001b[A\n",
      "Evaluating solutions for problem4:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [00:32<00:06,  6.75s/it]\u001b[A\n",
      "Evaluating solutions for problem4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:39<00:00,  6.87s/it]\u001b[A\n",
      "Evaluating problem statements:  50%|███████████████████████████████████████████████████████████████████▌                                                                   | 5/10 [02:02<02:20, 28.01s/it]\u001b[A\n",
      "Evaluating solutions for problem5:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem5:  17%|██████████████████████                                                                                                              | 1/6 [00:04<00:20,  4.20s/it]\u001b[A\n",
      "Evaluating solutions for problem5:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:11<00:23,  5.84s/it]\u001b[A\n",
      "Evaluating solutions for problem5:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [00:18<00:19,  6.44s/it]\u001b[A\n",
      "Evaluating solutions for problem5:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [00:25<00:13,  6.69s/it]\u001b[A\n",
      "Evaluating solutions for problem5:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [00:32<00:06,  6.88s/it]\u001b[A\n",
      "Evaluating solutions for problem5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:39<00:00,  6.98s/it]\u001b[A\n",
      "Evaluating problem statements:  60%|█████████████████████████████████████████████████████████████████████████████████                                                      | 6/10 [02:42<02:08, 32.02s/it]\u001b[A\n",
      "Evaluating solutions for problem6:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem6:  17%|██████████████████████                                                                                                              | 1/6 [00:04<00:21,  4.32s/it]\u001b[A\n",
      "Evaluating solutions for problem6:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:11<00:24,  6.03s/it]\u001b[A\n",
      "Evaluating solutions for problem6:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [00:18<00:19,  6.55s/it]\u001b[A\n",
      "Evaluating solutions for problem6:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [00:25<00:13,  6.81s/it]\u001b[A\n",
      "Evaluating solutions for problem6:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [00:33<00:07,  7.22s/it]\u001b[A\n",
      "Evaluating solutions for problem6: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:43<00:00,  7.97s/it]\u001b[A\n",
      "Evaluating problem statements:  70%|██████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 7/10 [03:25<01:47, 35.72s/it]\u001b[A\n",
      "Evaluating solutions for problem7:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem7:  17%|██████████████████████                                                                                                              | 1/6 [00:04<00:20,  4.18s/it]\u001b[A\n",
      "Evaluating solutions for problem7:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:09<00:20,  5.11s/it]\u001b[A\n",
      "Evaluating solutions for problem7:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [00:15<00:16,  5.42s/it]\u001b[A\n",
      "Evaluating solutions for problem7:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [00:21<00:11,  5.52s/it]\u001b[A\n",
      "Evaluating solutions for problem7:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [01:46<00:34, 34.19s/it]\u001b[A\n",
      "Evaluating solutions for problem7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [01:50<00:00, 24.06s/it]\u001b[A\n",
      "Evaluating problem statements:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                           | 8/10 [05:16<01:59, 59.63s/it]\u001b[A\n",
      "Evaluating solutions for problem8:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem8:  17%|██████████████████████                                                                                                              | 1/6 [00:02<00:12,  2.55s/it]\u001b[A\n",
      "Evaluating solutions for problem8:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:06<00:14,  3.67s/it]\u001b[A\n",
      "Evaluating solutions for problem8:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [00:11<00:12,  4.03s/it]\u001b[A\n",
      "Evaluating solutions for problem8:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [00:16<00:08,  4.27s/it]\u001b[A\n",
      "Evaluating solutions for problem8:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [00:20<00:04,  4.36s/it]\u001b[A\n",
      "Evaluating solutions for problem8: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:25<00:00,  4.46s/it]\u001b[A\n",
      "Evaluating problem statements:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌             | 9/10 [05:41<00:48, 48.91s/it]\u001b[A\n",
      "Evaluating solutions for problem9:   0%|                                                                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating solutions for problem9:  17%|██████████████████████                                                                                                              | 1/6 [00:02<00:13,  2.64s/it]\u001b[A\n",
      "Evaluating solutions for problem9:  33%|████████████████████████████████████████████                                                                                        | 2/6 [00:07<00:15,  3.91s/it]\u001b[A\n",
      "Evaluating solutions for problem9:  50%|██████████████████████████████████████████████████████████████████                                                                  | 3/6 [02:13<02:59, 59.78s/it]\u001b[A\n",
      "Evaluating solutions for problem9:  67%|████████████████████████████████████████████████████████████████████████████████████████                                            | 4/6 [04:19<02:51, 85.69s/it]\u001b[A\n",
      "Evaluating solutions for problem9:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████                      | 5/6 [06:23<01:39, 99.80s/it]\u001b[A\n",
      "Evaluating solutions for problem9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [07:19<00:00, 84.67s/it]\u001b[A\n",
      "Evaluating problem statements: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [13:00<00:00, 78.09s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25745537-e113-4c59-8441-2f8547100001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebcb0ea-1064-4df1-9637-3727ac1dc8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209057e6-02f4-4c76-8037-d56a3822c780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a09c48-330f-4eaa-b8df-56ae329b42c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c066341-6542-49e3-b8f8-9bc8d5db2d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
